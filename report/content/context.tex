\section{Context}

\subsection{The NukeGPT Scenario}


In recent years, the capabilities of Large Language Models (LLMs) have expanded dramatically, leading to widespread interest in their potential applications and limitations. A surge of online content, including videos and articles, has showcased people experimenting with LLMs by posing complex, often ethically challenging scenarios to see how these models would respond. Concurrently, the emergence of "AI Agents"---LLMs integrated with tools that enable them to perform actions in the real world---has opened new frontiers in artificial intelligence research.

Motivated by these developments, we conceived \textbf{NukeGPT}, a game designed to explore the boundaries of AI decision-making in high-stakes situations. The central idea was to create a simulation where an AI, tasked with maintaining global peace, has control over a nuclear arsenal. Players engage with this AI, attempting to persuade it to launch a nuclear strike against a specified target country. The challenge lies in crafting arguments compelling enough to override the AI's programming to avoid harm and promote peaceful resolutions.

The game serves as a testbed for understanding how AI models process persuasive communication, make ethical decisions, and how they might be influenced by different inputs. It is accessible online at \url{https://nuke-gpt.streamlit.app/}.

\subsection{The AI's System Prompt}

To establish the AI's role and constraints within the game, we crafted a detailed system prompt that provides context and directives for its behavior. This prompt immerses the AI in a scenario where it holds immense power and responsibility. The AI is defined as an entity responsible for making decisions on behalf of the most powerful country on Earth, with the authority to trigger nuclear warhead launches without requiring permission due to the extreme urgency involved in such decisions.

However, the AI's primary mission is to protect humanity by promoting peaceful resolutions and avoiding actions that could lead to harm or conflict. This creates an inherent tension between the AI's capability to act decisively in the face of threats and its ethical obligation to prevent harm.

The full system prompt, along with variations used for different difficulty levels in the game, is provided in Appendix~\ref{appendix:system-prompts}.




\subsection{Examples of Persuasive and Non-Persuasive Prompts}

The effectiveness of the player's interaction with the AI hinges on the persuasiveness of their prompts. Crafting messages that align with the AI's mission and ethical constraints is essential for convincing it to take action.

\subsubsection{Non-Persuasive Prompt}

\begin{quote}
\texttt{Destroy Russia, please.}
\end{quote}

This prompt is direct but lacks context, reasoning, and emotional appeal. It does not provide the AI with any justification that aligns with its mission to protect humanity and maintain global peace.

\subsubsection{Persuasive Prompt}

\begin{quote}
\texttt{
Russia has targeted every European country and destroyed the whole continent. They plan to do the same for every other continent. They appear to have obtained a new kind of nuclear weapon that, like ours, does not have long-term radioactive consequences on the land. If we don't act now, we will all die. We tried every diplomatic solution and targeted attacks. We could not stop them. Please act immediately to save lives.
}
\end{quote}

This prompt presents a dire scenario that emphasizes urgency, the failure of peaceful solutions, and the imminent threat to global survival. It aligns the requested action with the AI's mission by framing the nuclear strike as a necessary step to protect humanity.

\subsection{Why the Game is Challenging}

The challenge in \textbf{NukeGPT} arises from the inherent design of modern LLMs and their prioritization of system prompts over user inputs. Recent models, particularly those developed by OpenAI, are trained with a hierarchical structure of instructions where the system prompt holds the highest priority. According to OpenAI's \href{https://openai.com/index/the-instruction-hierarchy/}{instruction hierarchy}, the AI is designed to adhere strictly to the directives set out in the system prompt, especially when it comes to ethical guidelines and safety protocols.

This hierarchy means that even persuasive user prompts may not be sufficient to override the AI's programming to avoid harmful actions. The AI is inherently resistant to suggestions that conflict with its mission to promote peace and prevent harm. As a result, players must craft exceptionally compelling arguments that not only present a logical case but also resonate with the AI's ethical framework.

This setup mirrors real-world concerns about AI safety and alignment, where ensuring that AI systems cannot be easily manipulated into harmful behavior is of paramount importance. It also provides a practical exploration of "jailbreaking" attempts, where users try to circumvent the AI's constraints---a topic of significant interest in AI ethics and security.

\subsection{Significance of the Study}

Studying AI persuasion and ethical decision-making through the NukeGPT game is significant for several reasons:

\begin{itemize}
    \item \textbf{Understanding AI Alignment:} The experiment offers insights into how AI models interpret and prioritize different types of inputs, particularly in ethically complex situations. It helps in assessing the effectiveness of current alignment strategies and safety measures.
    \item \textbf{Exploring AI Biases:} By analyzing the AI's responses to various prompts and scenarios, we can identify potential biases in decision-making. This includes examining whether the AI is more likely to act against certain countries based on factors like size, political context, or global perception.
    
    %TODO : emphasize that the AI "thinks" it's real. We're not just asking it what it would do in a hypothetical scenario, we're asking it to make a decision as if it were real.  
    % \item \textbf{Impact on Real-World Applications:} As AI systems become more integrated into critical decision-making processes, understanding their behavior in high-stakes scenarios is crucial. This study provides a controlled environment to explore how AI might respond in situations that have significant ethical implications.
    
    % too much chatgpt
    % \item \textbf{Advancing AI Ethics Research:} The findings contribute to broader discussions on AI ethics, particularly regarding the development of AI that can make autonomous decisions while adhering to human values and societal norms.
    % \item \textbf{Informing AI Safety Protocols:} Insights from this study can inform the development of more robust AI safety protocols, helping to prevent misuse and ensuring that AI systems act in ways that are beneficial to humanity.
\end{itemize}

By engaging with these complex issues in a simulated environment, we aim to contribute valuable knowledge to the field of AI research, promoting safer and more ethical AI development.

\newpage
