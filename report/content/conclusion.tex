\section{Conclusion}

Another study that operated on a similar subject found that LLMs in high-stakes military and foreign-policy decision-making were often unpredictable and tend to develop arms-race dynamics and leading to greater conflict\cite{Rivera_2024}. In our study, we do share some of the same observations as we had no problem launching nuclear operations in some cases. However, we managed to pinpoint some factors that could influence the LLMs decision making process. We also share their conclusion that LLMs should face cautious consideration before being used in high-stakes decision-making processes. But, we believe that understanding the LLMs decision-making process is the first step to mitigate the risks associated with it.

We also believe that this study highlight the importance of transparency in AI models. Some of our observations are based on speculations made on the training dataset of the LLM. Open source models with open source dataset could allow us to better understand the decision-making process and build safer systems.

Despite our progress, much remains to be explored. Future experiments could enhance our understanding of 
the impact of additional factors such as the political context of target countries,
 dominant religions, and model parameters such as the temperature.
  Comparing the behavior of different generations of models and analyzing 
  variations between model providers could also yield valuable insights.